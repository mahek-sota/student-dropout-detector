# -*- coding: utf-8 -*-
"""random_forrest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10B1Y-hw4VF553feZ8T8PWyzI7KrrfYGt
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import matplotlib.pyplot as plt

data1 = pd.read_csv('factors_dropout.csv')
data2 = pd.read_csv('score_dropout.csv')

# Step 1: Clean and Prepare Dataset 1
data1['Target'] = data1['Target'].apply(lambda x: 1 if x == 'Dropout' else 0)

# Feature Engineering: Adding new features
data1['Approved_to_Enrolled'] = data1['Curricular units 1st sem (approved)'] / (
    data1['Curricular units 1st sem (enrolled)'] + 1e-5)
data1['Age_bin'] = pd.cut(data1['Age at enrollment'], bins=[15, 20, 25, 30, 35], labels=False)

X1 = data1[['Age at enrollment', 'Curricular units 1st sem (approved)',
            'Curricular units 1st sem (evaluations)', 'Unemployment rate', 'GDP',
            'Approved_to_Enrolled', 'Age_bin']]
y1 = data1['Target']

imputer = SimpleImputer(strategy='mean')  # Replace NaN with column mean
X1_imputed = imputer.fit_transform(X1)    # Impute missing values

scaler1 = StandardScaler()
X1_scaled = scaler1.fit_transform(X1_imputed)

smote = SMOTE(random_state=42)
X1_resampled, y1_resampled = smote.fit_resample(X1_scaled, y1)

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}



grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X1_resampled, y1_resampled)

rf1 = grid_search.best_estimator_
rf1_accuracy = cross_val_score(rf1, X1_resampled, y1_resampled, cv=5, scoring='accuracy').mean()
print("Best Random Forest Model 1 Accuracy:", rf1_accuracy)
print("Best Parameters for Model 1:", grid_search.best_params_)

# Feature Importance Plot
feature_importances = rf1.feature_importances_
feature_names = X1.columns
plt.figure(figsize=(10, 6))
plt.barh(feature_names, feature_importances)
plt.title("Feature Importance for Model 1")
plt.show()

# XGBoost Model for Comparison
xgb1 = XGBClassifier(n_estimators=200, max_depth=20, random_state=42)
xgb1.fit(X1_resampled, y1_resampled)
xgb1_accuracy = cross_val_score(xgb1, X1_resampled, y1_resampled, cv=5, scoring='accuracy').mean()
print("XGBoost Model 1 Accuracy:", xgb1_accuracy)

P1_train = rf1.predict_proba(X1_scaled)[:, 1]

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import cross_val_score

# Step 1: Split and Clean the Data
data2_split = data2['access;tests;tests_grade;exam;project;project_grade;assignments;result_points;result_grade;graduate;year;acad_year'].str.split(';', expand=True)
data2_split.columns = ['access', 'tests', 'tests_grade', 'exam', 'project', 'project_grade',
                       'assignments', 'result_points', 'result_grade', 'graduate', 'year', 'acad_year']

# Select relevant features
feature_columns = ['access', 'tests', 'tests_grade', 'exam', 'project', 'project_grade',
                   'assignments', 'result_points', 'year']

# Drop columns with all missing values
data2_clean = data2_split[feature_columns]
data2_clean = data2_clean.dropna(axis=1, how='all')  # Drop columns where all values are NaN

# Update feature_columns after dropping
feature_columns = data2_clean.columns.tolist()

# Convert to numeric and handle NaN values with imputation
data2_clean = data2_clean.apply(pd.to_numeric, errors='coerce')
imputer = SimpleImputer(strategy='mean')
X2_clean = imputer.fit_transform(data2_clean)

# Ensure target column is clean and aligned
y2 = pd.to_numeric(data2_split['graduate'], errors='coerce').dropna()
X2_clean = X2_clean[:len(y2)]  # Ensure X and y align in length

# Step 2: Feature Scaling
scaler2 = StandardScaler()
X2_scaled = scaler2.fit_transform(X2_clean)

# Step 3: Train Random Forest to Find Feature Importances
rf_temp = RandomForestClassifier(n_estimators=100, random_state=42)
rf_temp.fit(X2_scaled, y2)

# Get Feature Importances
importances = rf_temp.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print Feature Importances
print("Feature Importances for Model 2:")
print(feature_importance_df)

# Step 4: Select Top Features
top_features = feature_importance_df['Feature'].head(5).tolist()  # Top 5 features
print("\nTop Features Selected for Model 2:", top_features)

# Step 5: Retrain Model with Top Features
X2_top = pd.DataFrame(X2_clean, columns=feature_columns)[top_features]
X2_scaled_top = scaler2.fit_transform(X2_top)

# Handle Class Imbalance
smote = SMOTE(sampling_strategy=0.8, random_state=42)
X2_resampled, y2_resampled = smote.fit_resample(X2_scaled_top, y2)

# Train Calibrated Random Forest
rf2 = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)
rf2_calibrated = CalibratedClassifierCV(rf2, method='sigmoid', cv=5)
rf2_calibrated.fit(X2_resampled, y2_resampled)

# Step 6: Evaluate Model Accuracy
rf2_accuracy = cross_val_score(rf2_calibrated, X2_resampled, y2_resampled, cv=5, scoring='accuracy').mean()
print("\nBalanced and Calibrated Random Forest Model 2 Accuracy (Top Features):", rf2_accuracy)

# ======================= Meta-Model Training =======================
# Step 6: Combine Predictions into a Meta-Model
# Combine Predictions into Meta-Dataset
# Generate Model 1 and Model 2 Probabilities for Meta-Model Training
P1_train = rf1.predict_proba(X1_scaled)[:, 1]
P2_train = rf2_calibrated.predict_proba(X2_scaled_top)[:, 1]

# Combine Predictions into Meta-Dataset
meta_data = pd.DataFrame({'Model1_Prob': P1_train[:len(P2_train)], 'Model2_Prob': P2_train})
meta_target = y2_resampled[:len(meta_data)]  # Ensure target aligns with combined data length
meta_target = y2[:len(meta_data)]  # Ensure target aligns with combined data length

# Stratified Train-Test Split
X_meta_train, X_meta_test, y_meta_train, y_meta_test = train_test_split(
    meta_data, meta_target, test_size=0.3, random_state=42, stratify=meta_target
)

# Train Logistic Regression Meta-Model with Regularization
meta_model = LogisticRegression(C=0.5, solver='liblinear')
meta_model.fit(X_meta_train, y_meta_train)

# Evaluate Meta-Model
meta_pred_test = meta_model.predict(X_meta_test)
meta_accuracy = accuracy_score(y_meta_test, meta_pred_test)
print("Meta-Model Accuracy on Test Data:", meta_accuracy)

# Cross-Validation
meta_cv_accuracy = cross_val_score(meta_model, meta_data, meta_target, cv=5, scoring='accuracy').mean()
print("Meta-Model Cross-Validation Accuracy:", meta_cv_accuracy)

# ======================= Final Prediction =======================

def print_predictions(test_case_name, P1, P2, final_prediction):
    """
    Utility function to print model probabilities and final prediction.
    """
    print(f"\n=== {test_case_name} ===")
    print(f"Model 1 Dropout Probability: {P1[0]:.4f}")
    print(f"Model 2 Dropout Probability: {P2[0]:.4f}")
    print("Final Prediction:", "Dropout" if final_prediction[0] == 1 else "Graduate")


# Ensure feature alignment for Model 1
model1_features = ['Age at enrollment', 'Curricular units 1st sem (approved)',
                   'Curricular units 1st sem (evaluations)', 'Unemployment rate',
                   'GDP', 'Approved_to_Enrolled', 'Age_bin']

# Ensure feature alignment for Model 2
model2_features = top_features  # Dynamically updated top features

# Function to align features
def align_features(data, feature_list):
    """
    Aligns input DataFrame columns to match the model's training feature list.
    Missing features are filled with 0.
    """
    aligned_data = pd.DataFrame(0, index=range(len(data)), columns=feature_list)
    for col in data.columns:
        if col in aligned_data.columns:
            aligned_data[col] = data[col]
    return aligned_data


# ================== TEST CASES ==================

# Test Case 1: Likely Dropout
new_data1_dropout = pd.DataFrame({
    'Age at enrollment': [19], 'Curricular units 1st sem (approved)': [6],
    'Curricular units 1st sem (evaluations)': [6], 'Unemployment rate': [13.9], 'GDP': [0.79],
    'Approved_to_Enrolled': [0.9], 'Age_bin': [1]
})
P1_dropout = rf1.predict_proba(scaler1.transform(imputer.transform(align_features(new_data1_dropout, model1_features))))[:, 1]

new_data2_dropout = pd.DataFrame({
    'result_points': [80], 'exam': [70], 'project': [85], 'tests': [90], 'access': [1]
})
P2_dropout = rf2_calibrated.predict_proba(scaler2.transform(align_features(new_data2_dropout, model2_features)))[:, 1]

meta_input_dropout = pd.DataFrame({'Model1_Prob': P1_dropout, 'Model2_Prob': P2_dropout})
final_prediction_dropout = meta_model.predict(meta_input_dropout)
print_predictions("Test Case 1 - Likely Dropout", P1_dropout, P2_dropout, final_prediction_dropout)


# Test Case 2: Likely Graduate
new_data1_graduate = pd.DataFrame({
    'Age at enrollment': [22], 'Curricular units 1st sem (approved)': [6],
    'Curricular units 1st sem (evaluations)': [6], 'Unemployment rate': [5.0], 'GDP': [3.5],
    'Approved_to_Enrolled': [1.0], 'Age_bin': [2]
})
P1_graduate = rf1.predict_proba(scaler1.transform(imputer.transform(align_features(new_data1_graduate, model1_features))))[:, 1]

new_data2_graduate = pd.DataFrame({
    'result_points': [95], 'exam': [90], 'project': [95], 'tests': [85], 'access': [2]
})
P2_graduate = rf2_calibrated.predict_proba(scaler2.transform(align_features(new_data2_graduate, model2_features)))[:, 1]

meta_input_graduate = pd.DataFrame({'Model1_Prob': P1_graduate, 'Model2_Prob': P2_graduate})
final_prediction_graduate = meta_model.predict(meta_input_graduate)
print_predictions("Test Case 2 - Likely Graduate", P1_graduate, P2_graduate, final_prediction_graduate)


# Test Case 3: New Dropout Case
new_data1_dropout2 = pd.DataFrame({
    'Age at enrollment': [20], 'Curricular units 1st sem (approved)': [2],
    'Curricular units 1st sem (evaluations)': [3], 'Unemployment rate': [12.5], 'GDP': [1.5],
    'Approved_to_Enrolled': [0.6], 'Age_bin': [1]
})
P1_dropout2 = rf1.predict_proba(scaler1.transform(imputer.transform(align_features(new_data1_dropout2, model1_features))))[:, 1]

new_data2_dropout2 = pd.DataFrame({
    'result_points': [65], 'exam': [60], 'project': [70], 'tests': [55], 'access': [1]
})
P2_dropout2 = rf2_calibrated.predict_proba(scaler2.transform(align_features(new_data2_dropout2, model2_features)))[:, 1]

meta_input_dropout2 = pd.DataFrame({'Model1_Prob': P1_dropout2, 'Model2_Prob': P2_dropout2})
final_prediction_dropout2 = meta_model.predict(meta_input_dropout2)
print_predictions("Test Case 3 - New Dropout", P1_dropout2, P2_dropout2, final_prediction_dropout2)


# Test Case 4: New Graduate Case
new_data1_graduate2 = pd.DataFrame({
    'Age at enrollment': [23], 'Curricular units 1st sem (approved)': [7],
    'Curricular units 1st sem (evaluations)': [7], 'Unemployment rate': [4.0], 'GDP': [4.5],
    'Approved_to_Enrolled': [1.0], 'Age_bin': [2]
})
P1_graduate2 = rf1.predict_proba(scaler1.transform(imputer.transform(align_features(new_data1_graduate2, model1_features))))[:, 1]

new_data2_graduate2 = pd.DataFrame({
    'result_points': [98], 'exam': [95], 'project': [99], 'tests': [92], 'access': [2]
})
P2_graduate2 = rf2_calibrated.predict_proba(scaler2.transform(align_features(new_data2_graduate2, model2_features)))[:, 1]

meta_input_graduate2 = pd.DataFrame({'Model1_Prob': P1_graduate2, 'Model2_Prob': P2_graduate2})
final_prediction_graduate2 = meta_model.predict(meta_input_graduate2)
print_predictions("Test Case 4 - New Graduate", P1_graduate2, P2_graduate2, final_prediction_graduate2)

print("Model 1 Probabilities for Dropout Test Case:", P1_dropout)
print("Model 2 Probabilities for Dropout Test Case:", P2_dropout)

print("Model 1 Probabilities for Graduate Test Case:", P1_graduate)
print("Model 2 Probabilities for Graduate Test Case:", P2_graduate)

print("Model 1 Probabilities for New Dropout Case:", P1_dropout2)
print("Model 2 Probabilities for New Dropout Case:", P2_dropout2)

print("Model 1 Probabilities for New Graduate Case:", P1_graduate2)
print("Model 2 Probabilities for New Graduate Case:", P2_graduate2)

